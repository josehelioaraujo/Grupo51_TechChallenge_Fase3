{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/josehelioaraujo/Grupo51_TechChallenge_Fase3/blob/main/Grupo51_TechChallenge_Fase3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# **PosTech Inteligência Artificial Para Desenvolvedores - Fiap**\n",
        "###  **Projeto Challenge Fase 3 - Grupo 51**\n",
        "   \n",
        "\n",
        "### **Grupo 51/Alunos:**\n",
        "  \n",
        "| Matrícula                       | Nome do Aluno  | Email                                                  |\n",
        "| ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |\n",
        "| RM355027 | José Hélio Araujo Andrade  | helioandrade@hotmail.com|\n",
        "| RM356210 | Bernardo Guimarães Tinti   | betinti@hotmail.com |\n",
        "\n",
        "\n",
        "# Entregáveis\n",
        "\n",
        "|        |  |\n",
        "| ------ |  |\n",
        "| Repositório no GitHub | https://github.com/josehelioaraujo/Grupo51_TechChallenge_Fase3   |  \n",
        "| Video Apresentação no Youtube | coloque o link ak    |  \n",
        "\n",
        "\n",
        "\n",
        "### Arquivos no Google Colab\n",
        "| Nome do Arquivo                               | Descrição                                                  | Link de Acesso                                                  |\n",
        "| ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |\n",
        "| Arquivo Colab Parte 1  | Preparação do Dados  | [![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1QBcfFYk8ij5GZZ8lHKjMhzXUnTgcXUQN#scrollTo=lFz7PZnJBCg) |\n",
        "| Arquivo Colab Parte 2  | Geração de Peguntas e Respostas - Sem Fine Tuning  | [![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1LxAub1TRzK8hwGp437d9hWDZimmyO4mh#scrollTo=yIuqPWd5TnGs) |\n",
        "| Arquivo Colab Parte 3  | Treinamento do Modelo e Geração de Perguntas e Respostas | [![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1COgE03H7Qj6o-XKoGYVxkmql3cxFOMAX#scrollTo=N5sDrF2M-qZi) |\n",
        "\n",
        "\n",
        "### Datasets no Hugging Face\n",
        "\n",
        "| Datasets                               | Descrição                                                  | Link de Acesso                                                  |\n",
        "| ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |\n",
        "| Dataset Original |Dataset original que será usado no Fine Tuning no treinamento do modelo  | [Acessar](https://huggingface.co/datasets/helioandrade/amazon-titles-jsonl) |\n",
        "| Datasets com 'Chunks'  | Datasets que foram particionados a partir do dataset original | [Acessar](https://huggingface.co/datasets/helioandrade/amazon-titles) |\n",
        "| Datasets com Fine Tuning  | Datasets com Fine Tuning e treinados com perguntas e respostas | [Acessar](https://huggingface.co/datasets/helioandrade/amazon-titles-questions-answering) |\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**Ferramentas utilizadas**\n",
        "- [Conversor texto/audio ](https://crikk.com)- usado na criação do audio da narração\n",
        "- OBS Studio - usado na gravação do video de apresentação\n",
        "- DaVinci Resolve - usado na montagem e edição do video de apresentação\n",
        "\n",
        "\n",
        "# O Problema\n",
        "\n",
        "No Tech Challenge desta fase, você precisa executar o fine-tuning de um foundation model (Llama, BERT, MISTRAL etc.), utilizando o dataset \"The AmazonTitles-1.3MM\". O modelo treinado deverá:\n",
        "\n",
        "- Receber perguntas com um contexto obtido por meio do arquivo json “trn.json” que está contido dentro do dataset.\n",
        "- A partir do prompt formado pela pergunta do usuário sobre o título do produto, o modelo deverá gerar uma resposta baseada na pergunta do usuário trazendo como resultado do aprendizado do fine-tuning os dados da sua descrição.\n",
        "\n",
        "## Fluxo de trabalho atualizado:\n",
        "\n",
        "1. **Escolha do Dataset**:\n",
        "   - **Descrição**: O The AmazonTitles-1.3MM consiste em consultas textuais reais de usuários e títulos associados de produtos relevantes encontrados na Amazon e suas descrições, medidos por ações implícitas ou explícitas dos usuários.\n",
        "\n",
        "2. **Preparação do Dataset**:\n",
        "   - Faça o download do dataset AmazonTitles-1.3MM e utilize o arquivo “trn.json”. Nele, você utilizará as colunas “title” e “content”, que contêm título e descrição respectivamente. Prepare os prompts para o fine-tuning garantindo que estejam organizados de maneira adequada para o treinamento do modelo escolhido. Limpe e pré-processe os dados conforme necessário para o modelo escolhido.\n",
        "\n",
        "3. **Chamada do Foundation Model**:\n",
        "   - Importe o foundation model que será utilizado e faça um teste apresentando o resultado atual do modelo antes do treinamento (para que se obtenha uma base de análise após o fine-tuning), e então será possível avaliar a diferença do resultado gerado.\n",
        "\n",
        "4. **Execução do Fine-Tuning**:\n",
        "   - Execute o fine-tuning do foundation model selecionado (por exemplo, BERT, GPT, Llama) utilizando o dataset preparado. Documente o processo de fine-tuning, incluindo os parâmetros utilizados e qualquer ajuste específico realizado no modelo.\n",
        "\n",
        "5. **Geração de Respostas**:\n",
        "   - Configure o modelo treinado para receber perguntas dos usuários. O modelo deverá gerar uma resposta baseada na pergunta do usuário e nos dados provenientes do fine-tuning, incluindo as fontes fornecidas.\n",
        "\n",
        "## O que esperamos para o entregável?\n",
        "\n",
        "- Documento detalhando o processo de seleção e preparação do dataset.\n",
        "- Descrição do processo de fine-tuning do modelo, com detalhes dos parâmetros e ajustes utilizados. Código-fonte do processo de fine-tuning.\n",
        "- Um vídeo demonstrando o modelo treinado gerando respostas a partir de perguntas do usuário e utilizando o contexto obtido por meio do treinamento com o fine-tuning."
      ],
      "metadata": {
        "id": "48mnS5Es6O_y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Esboço da Solução do Problema\n",
        "\n",
        "## 1. Preparação de Dados\n",
        "\n",
        "- **Download do Dataset**:\n",
        "  - Obter o dataset \"The AmazonTitles-1.3MM\" e localizar o arquivo \"trn.json\".\n",
        "  \n",
        "- **Análise do Dataset**:\n",
        "  - Examinar as colunas “title” e “content” para entender a estrutura e o conteúdo.\n",
        "\n",
        "- **Limpeza e Pré-processamento**:\n",
        "  - Remover dados duplicados e irrelevantes.\n",
        "  - Normalizar texto (remover pontuação, converter para minúsculas, etc.).\n",
        "  - Organizar os dados em prompts adequados para o treinamento do modelo.\n",
        "\n",
        "- **Divisão dos Dados**:\n",
        "  - Dividir o dataset em conjuntos de treino e validação para evitar overfitting.\n",
        "\n",
        "## 2. Fine-Tuning e Treinamento do Modelo\n",
        "\n",
        "- **Escolha do Foundation Model**:\n",
        "  - Selecionar um modelo apropriado (ex: BERT, Llama) com base na tarefa.\n",
        "\n",
        "- **Configuração do Treinamento**:\n",
        "  - Definir hiperparâmetros como taxa de aprendizado, número de épocas e tamanho do batch.\n",
        "\n",
        "- **Execução do Fine-Tuning**:\n",
        "  - Treinar o modelo utilizando o dataset preparado.\n",
        "  - Monitorar o processo para ajustes em tempo real, se necessário.\n",
        "\n",
        "- **Documentação do Processo**:\n",
        "  - Registrar todos os parâmetros utilizados e ajustes feitos durante o treinamento.\n",
        "\n",
        "## 3. Avaliação dos Resultados Com e Sem Fine-Tuning\n",
        "\n",
        "- **Avaliação Inicial**:\n",
        "  - Testar o modelo antes do fine-tuning para estabelecer uma linha de base.\n",
        "\n",
        "- **Avaliação Pós Fine-Tuning**:\n",
        "  - Realizar testes com o modelo ajustado e comparar os resultados com o modelo original.\n",
        "  \n",
        "- **Métricas de Avaliação**:\n",
        "  - Utilizar métricas como precisão, recall e F1-score para quantificar a melhoria.\n",
        "\n",
        "## 4. Conclusões\n",
        "\n",
        "- **Resultados Obtidos**:\n",
        "  - Resumir as melhorias observadas no desempenho do modelo após o fine-tuning.\n",
        "  \n",
        "- **Impacto do Fine-Tuning**:\n",
        "  - Discutir como o fine-tuning afetou a qualidade das respostas geradas.\n",
        "\n",
        "## 5. Sugestões de Melhorias\n",
        "\n",
        "- **Aprimoramento do Dataset**:\n",
        "  - Incluir mais dados ou diversificar as fontes para melhorar a robustez do modelo.\n",
        "\n",
        "- **Ajustes em Hiperparâmetros**:\n",
        "  - Experimentar diferentes configurações de hiperparâmetros para otimizar o desempenho.\n",
        "\n",
        "- **Feedback dos Usuários**:\n",
        "  - Implementar um sistema de feedback para coletar opiniões dos usuários e ajustar o modelo conforme necessário.\n",
        "\n",
        "- **Atualização Contínua do Modelo**:\n",
        "  - Estabelecer um ciclo de atualização regular do modelo com novos dados e melhorias.\n"
      ],
      "metadata": {
        "id": "5I3ObxcYALWN"
      }
    }
  ]
}